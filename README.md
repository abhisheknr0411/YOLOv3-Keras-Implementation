# YOLOv3-Keras-Implementation

This is a basic Keras implementation of the YOLOv3 architecture for object detection using **Convolutional Neural Networks**.

You only look once (YOLO) at an image to predict what objects are present and where they are present using a single convolutional network. YOLO predicts multiple bounding boxes and class probabilities for those boxes.

YOLO v3 uses a variant of Darknet, which originally has **53 layer network trained on Imagenet**. For the task of detection, 53 more layers are stacked onto it, giving us a 106 layer fully convolutional underlying architecture for YOLO v3.

The most salient feature of v3 is that **it makes detections at three different scales**. YOLO is a fully convolutional network and its eventual output is generated by applying a 1 x 1 kernel on a feature map. In YOLO v3, the detection is done by **applying 1 x 1 detection kernels** on feature maps of three different sizes at three different places in the network.

* YOLO v3 makes prediction at three scales, which are precisely given by downsampling the dimensions of the input image by 32, 16 and 8 respectively.
* **The first detection is made by the 82nd layer**. For the first 81 layers, the image is down sampled by the network, such that the 81st layer has a stride of 32. If we have an image of 416 x 416, the resultant feature map would be of size 13 x 13. 
* One detection is made here using the 1 x 1 detection kernel, giving us a detection feature map of 13 x 13 x 255.
* Then, the feature map from layer 79 is subjected to a few convolutional layers before being up sampled by 2x to dimensions of 26 x 26. 
* This feature map is then depth concatenated with the feature map from layer 61. 
* Then the combined feature maps is again subjected a few 1 x 1 convolutional layers to fuse the features from the earlier layer (61). 
* Then, **the second detection is made by the 94th layer**, yielding a detection feature map of 26 x 26 x 255.

* A similar procedure is followed again, where the feature map from layer 91 is subjected to few convolutional layers before being depth concatenated with a feature map from layer 36. Like before, a few 1 x 1 convolutional layers follow to fuse the information from the previous layer (36). 
* We make the final of the 3 at 106th layer, yielding feature map of size 52 x 52 x 255.

Just follow along the Jupyter Notebook provided, and you can easily download the yolov3.weights from [here](https://pjreddie.com/media/files/yolov3.weights)

Hope you enjoy detecting objects with this easy and one of the fastest architecture for object detection.
